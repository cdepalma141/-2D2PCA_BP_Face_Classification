{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify_Face Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Notebook is used to test the Neural network using a webcam and the previously generated model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from Preprocessing.DCT import DCT2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in projection matrices \n",
    "X = np.load(\"./PP_Data/X.npy\")\n",
    "Z = np.load(\"./PP_Data/Z.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/connordepalma/anaconda3/envs/testenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CLASSES = [\"Connor\", \"Dad\", \"Maddie\", \"Mom\"] # Create classification labels based on categorical labels\n",
    "model = load_model(\"./Models/model.hdf5\") # load previously generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to recognize faces using the variables loaded above\n",
    "# Since the function would require a larger number of parameters I chose to not place it into its own python package\n",
    "# like for PCA2D, DCT2D, etc.\n",
    "# The method for getting a prediction and placing labels is based on \n",
    "# https://www.pyimagesearch.com/2016/09/26/a-simple-neural-network-with-python-and-keras/\n",
    "\n",
    "def recognize_faces():\n",
    "    \n",
    "    # Load the haarcascade provided by OpenCV for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")    \n",
    "    \n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "    success = webcam.isOpened()\n",
    "    if success == False:\n",
    "        print('Error: Camera could not be opened')\n",
    "    else:\n",
    "        print('Success: Grabbed the camera')\n",
    "    \n",
    "    p = 0 # padding for cropped image if necessary\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = webcam.read()\n",
    "        frame = cv2.flip(frame, 1) # Otherwise video is not mirrored\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Get grayscale frame\n",
    "        \n",
    "        # Detect faces in current frame\n",
    "        faces = face_cascade.detectMultiScale(frame, scaleFactor=1.5, minNeighbors=5)\n",
    "        if ret: # ensure frame is captured\n",
    "            for (x,y,w,h) in faces:\n",
    "                # Loop through all faces in frame and perform classification\n",
    "                # Place rectangle around detected faces \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2);\n",
    "                \n",
    "                # Get cropped face frame\n",
    "                cropped_gray = gray[y-p+1:y+h+p, x-p+1:x+w+p]\n",
    "                # Perform preprocessing similar to what was done for the training set\n",
    "                # Ensure scaling matches scaling done in Preprocessing step\n",
    "                scaled = cv2.resize(cropped_gray, (300,300), interpolation=cv2.INTER_LINEAR)\n",
    "                norm_img = np.zeros((300,300))\n",
    "                norm_img = cv2.normalize(scaled, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                dct_image = np.uint8(DCT2D(norm_img).dct_compression())\n",
    "                # Use projection matrices from the training data\n",
    "                # to transform captured face into principle component space of the training images\n",
    "                face = Z.T @ dct_image @ X\n",
    "                # flatten PC space into feature vector\n",
    "                features = np.array([face.flatten()])\n",
    "                \n",
    "                # use model to make prediction and capture highest probable result\n",
    "                probs = model.predict(features)[0]\n",
    "                prediction = probs.argmax(axis=0)\n",
    "\n",
    "                \n",
    "                # If the prediction has a high enough accuracy based on the model\n",
    "                # display the corresponding label on top of the face being detected\n",
    "                label = \"\"\n",
    "                if probs[prediction] > .60:\n",
    "                    label = \"{}: {:.2f}%\".format(CLASSES[prediction],\n",
    "                    probs[prediction] * 100)\n",
    "\n",
    "                    cv2.putText(frame, label, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                1.0, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow(\"image\", frame)\n",
    "        \n",
    "        # Monitor keystrokes\n",
    "        k = cv2.waitKey(1)\n",
    "\n",
    "        if k & 0xFF == ord('q'):\n",
    "            # Press q to quit\n",
    "            print(\"Quitting...\")\n",
    "            break\n",
    "       \n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Grabbed the camera\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "recognize_faces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
